<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>My Music Playlist</title>
  <style>
    body {
      font-family: sans-serif;
      background-color: #f4f4f4;
      margin: 0;
      padding: 20px;
    }
    #visualizer {
      display: block;
      margin: 0 auto 20px;
      background-color: black;
      width: 760px;
      height: 190px;
    }
    ul#playlist {
      list-style: none;
      padding: 0;
    }
    ul#playlist li {
      padding: 8px;
      cursor: pointer;
      border-bottom: 1px solid #ccc;
    }
    ul#playlist li:hover {
      background-color: #e0e0e0;
    }
    audio {
      display: block;
      margin-top: 20px;
      width: 100%;
    }
  </style>
</head>
<body>
  <!-- Visualizer Canvas -->
  <canvas id="visualizer" width="760" height="190"></canvas>

  <!-- Playlist Area -->
  <ul id="playlist"></ul>

  <!-- Audio Player -->
  <audio id="audio-player" controls></audio>

  <script>
    const playlistEl = document.getElementById("playlist");
    const audioPlayer = document.getElementById("audio-player");

    // Retrieve playlist from localStorage
    const storedPlaylist = localStorage.getItem('playlist');
    let playlistData = [];
    if (storedPlaylist) {
      playlistData = JSON.parse(storedPlaylist);
    }

    // Populate playlist
    playlistData.forEach((track, index) => {
      const li = document.createElement("li");
      li.textContent = track.title;
      li.title = track.comments || "";
      li.addEventListener("click", () => {
        audioPlayer.src = track.src;
        audioPlayer.play();
      });
      playlistEl.appendChild(li);
    });

    // Visualizer logic
    const canvas = document.getElementById("visualizer");
    const ctx = canvas.getContext("2d");
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioCtx.createAnalyser();
    const source = audioCtx.createMediaElementSource(audioPlayer);
    source.connect(analyser);
    analyser.connect(audioCtx.destination);
    analyser.fftSize = 2048;
    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    function draw() {
      requestAnimationFrame(draw);
      analyser.getByteTimeDomainData(dataArray);
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 2;
      ctx.strokeStyle = "lightblue";
      ctx.beginPath();

      const sliceWidth = canvas.width / bufferLength;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const v = dataArray[i] / 128.0;
        const y = v * canvas.height / 2;
        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }
        x += sliceWidth;
      }

      ctx.lineTo(canvas.width, canvas.height / 2);
      ctx.stroke();
    }

    // Auto-start visualizer on any interaction
    function resumeAudioContext() {
      if (audioCtx.state === "suspended") {
        audioCtx.resume();
      }
    }

    // Start visualizer when user interacts
    document.addEventListener("click", resumeAudioContext);
    document.addEventListener("keydown", resumeAudioContext);
    draw();
  </script>
</body>
</html>
